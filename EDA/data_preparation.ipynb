{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import datetime\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = os.path.abspath('..')\n",
    "DATASET = 'COLLAB'\n",
    "## Possible LIST : DD, ENZYMES, PROTEINS / REDDIT-MULTI-12K, COLLAB (Exhaustive tasks)\n",
    "#DATASET = 'REDDIT-MULTI-12K'\n",
    "DATA_DIR = p + '/data/' + DATASET\n",
    "\n",
    "HEADER = None\n",
    "NODE_LAB = True\n",
    "NODE_ATT = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This folder contains the following comma separated text files \n",
    "(replace DS by the name of the dataset):\n",
    "\n",
    "$n$ = total number of nodes\n",
    "\n",
    "$m$ = total number of edges\n",
    "\n",
    "$N$ = number of graphs\n",
    "\n",
    "(1) DS_A.txt (m lines) \n",
    "\t\n",
    "    sparse (block diagonal) adjacency matrix for all graphs,\n",
    "\t\n",
    "    each line corresponds to (row, col) resp. (node_id, node_id)\n",
    "\n",
    "(2) DS_graph_indicator.txt (n lines)\n",
    "\t\n",
    "    column vector of graph identifiers for all nodes of all graphs,\n",
    "\t\n",
    "    the value in the i-th line is the graph_id of the node with node_id i\n",
    "\n",
    "(3) DS_graph_labels.txt (N lines) \n",
    "\t\n",
    "    class labels for all graphs in the dataset,\n",
    "\t\n",
    "    the value in the i-th line is the class label of the graph with graph_id i\n",
    "\n",
    "(4) DS_node_labels.txt (n lines)\n",
    "\n",
    "\tcolumn vector of node labels,\n",
    "\n",
    "    the value in the i-th line corresponds to the node with node_id i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_A = pd.read_csv(DATA_DIR + '/' + DATASET + '_A.txt', header = HEADER)\n",
    "ds_gInd = pd.read_csv(DATA_DIR + '/' + DATASET + '_graph_indicator.txt', header = HEADER)\n",
    "ds_gLab = pd.read_csv(DATA_DIR + '/' + DATASET + '_graph_labels.txt', header = HEADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_class_indexed_one = (min(ds_gLab[0]) > 0)\n",
    "is_graph_indexed_one = (min(ds_gInd[0]) > 0)\n",
    "is_node_indexed_one = (min(ds_gInd[0]) > 0)\n",
    "\n",
    "if(is_class_indexed_one):\n",
    "    ds_gLab = ds_gLab - 1\n",
    "if(is_graph_indexed_one):\n",
    "    ds_gInd = ds_gInd - 1\n",
    "if(is_node_indexed_one):\n",
    "    ds_A = ds_A - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of index starting from 1, we have to adjust them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No node labels\n",
      "No node attributes\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ds_nLab = pd.read_csv(DATA_DIR + '/' + DATASET + '_node_labels.txt', header = HEADER)\n",
    "except IOError:\n",
    "    NODE_LAB = False\n",
    "    print(\"No node labels\")\n",
    "    \n",
    "try:\n",
    "    ds_nAtt = pd.read_csv(DATA_DIR + '/' + DATASET + '_node_attributes.txt', header = HEADER)\n",
    "except IOError:\n",
    "    NODE_ATT = False\n",
    "    print(\"No node attributes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(ds_gLab[0].unique())\n",
    "n_graphs = len(ds_gLab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is too exhaustive when the total number of edges |E| > 10M\n",
    "#print(datetime.datetime.now())\n",
    "#edge_to_graph = ds_A[0].apply(lambda x : ds_gInd[0][x])\n",
    "#y_label = edge_to_graph.apply(lambda x : ds_gLab[0][x])\n",
    "#ds_A = ds_A.assign(gL = edge_to_graph)\n",
    "#ds_A = ds_A.assign(y = y_label)\n",
    "#print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [3:34:00<00:00,  2.57s/it]  \n"
     ]
    }
   ],
   "source": [
    "graph_index_list = ds_gLab.index.values\n",
    "graph_list = []\n",
    "\n",
    "#for i in graph_index_list:\n",
    "for i in tqdm.tqdm(graph_index_list):\n",
    "    corresp_node_list = ds_gInd[ds_gInd[0] == i].index.values\n",
    "    corresp_edge_list = ds_A[ds_A[0].isin(corresp_node_list)]\n",
    "    edgelist = corresp_edge_list.apply(lambda x : (x[0],x[1]), axis = 1).tolist()\n",
    "    ## Graph Attributes -> Graph Label\n",
    "    graph_list.append(nx.Graph(edgelist, y = ds_gLab[0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-18 20:49:50.601323\n",
      "False\n",
      "2018-10-18 20:49:50.601445\n",
      "False\n",
      "2018-10-18 20:49:50.601533\n"
     ]
    }
   ],
   "source": [
    "## Node Label -> OneHot vector? RexYing DiffPool chamzohagi\n",
    "print(datetime.datetime.now()) \n",
    "if(NODE_LAB):\n",
    "    for g in graph_list:\n",
    "        for pt in g.nodes():\n",
    "            g.node[pt]['label'] = ds_nLab[0][pt]\n",
    "print(datetime.datetime.now())\n",
    "## Node Attributes -> Node Attributes\n",
    "if(NODE_ATT):\n",
    "    for g in graph_list:\n",
    "        for pt in g.nodes:\n",
    "            g.node[pt]['attributes'] = ds_nAtt[0][pt]\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(p + '/pkls'):\n",
    "    os.makedirs(p + '/pkls')\n",
    "with open(p + '/pkls/' + DATASET + '_graphlist.pkl', 'wb') as f:\n",
    "    pickle.dump(graph_list,f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
